## Tokenization
Tokenization is at the heart of much weirdness of LLMs.

- Why can't LLM spell words? **Tokenization**
- Why can't LLM do super simple string processing tasks like reversing a string? **Tokenization**
- Why is LLM worse at non-English language (e.g Japanese, Chinese) **Tokenization**
- Why did GPT-2 have more than necessary trouble coding in Python ? **Tokenization**
- Why did my LLM abruptly halt when is sees the string "<|endoftext|>" ? **Tokenization**
- Why is this weird warning I get about a "trailing whitespace"? **Tokenization**
- Why the LLM break if I ask about a "SolidGoldMagikarp"? **Tokenization**
- Why to prefer to use YAML over JSON with LLMs? **Tokenization**
- Why LLM is not actually end-to-end language modeling? **Tokenization**
- What is the real root of suffering? **Tokenization**