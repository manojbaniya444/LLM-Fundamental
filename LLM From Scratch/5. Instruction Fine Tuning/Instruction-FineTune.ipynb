{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyP1bV36vn2JYHZ8XYf42V+1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## Instruction Fine Tuning\n","A pretrained model is called a foundational model or base model and is good at text completion, but it is not good at following instructions, so in order to follow instruction and act like a chatbot to folow user instruction and answer question we need another training step which is called Instruction Fine Tuning.\n","\n","Instruction Fine Tuning is another type of fine tuning where we train our model with special prompt which has instruction input and the output from that context. So model learns to answer the correct answer utitlizing its understanding of natural language at the pretraining stage."],"metadata":{"id":"hJoM6ghmmFys"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CdTz1ssQl_jy","executionInfo":{"status":"ok","timestamp":1736844735347,"user_tz":-345,"elapsed":5643,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"64db2914-6d7f-4b1d-8709-646905599982"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of entries: 1100\n"]}],"source":["# Getting our data\n","import json\n","import os\n","import urllib\n","\n","\n","def download_and_load_file(file_path, url):\n","\n","    if not os.path.exists(file_path):\n","        with urllib.request.urlopen(url) as response:\n","            text_data = response.read().decode(\"utf-8\")\n","        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n","            file.write(text_data)\n","    else:\n","        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n","            text_data = file.read()\n","\n","    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n","        data = json.load(file)\n","\n","    return data\n","\n","\n","file_path = \"instruction-data.json\"\n","url = (\n","    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n","    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",")\n","\n","data = download_and_load_file(file_path, url)\n","print(\"Number of entries:\", len(data))"]},{"cell_type":"code","source":["print(\"Example entry:\\n\", data[10])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BNKtfQVWnEpi","executionInfo":{"status":"ok","timestamp":1736844735348,"user_tz":-345,"elapsed":13,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"e862deec-16f8-4480-f70c-a1bf27b11d15"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Example entry:\n"," {'instruction': 'What is the contraction for \"will not\"?', 'input': '', 'output': 'The contraction for \"will not\" is \"won\\'t\".'}\n"]}]},{"cell_type":"code","source":["print(\"Another example entry:\\n\", data[100])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A2Exf7Ycn5iV","executionInfo":{"status":"ok","timestamp":1736844735348,"user_tz":-345,"elapsed":10,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"35e3f7f0-52ee-4669-9428-d8750dea540d"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Another example entry:\n"," {'instruction': 'Name a synonym for \"happiness.\"', 'input': '', 'output': 'A synonym for \"happiness\" is \"joy.\"'}\n"]}]},{"cell_type":"markdown","source":["### **Prompt formatting**\n","To fine tune in **Supervised Instruction FineTune** way we need to curate a dataset where the input, instruction and output is formatted.\n","\n","Some common ways to format is **Alpaca Format**\n","\n","### **Aplaca prompt Template**\n","Below is an instruction that describes a task. Write a resonse that appropriately completes the requets.\n","`### Instruction:`\n","\n","Identify the odd one out.\n","\n","`### Input:`\n","\n","\"coke\", \"pepsi\", \"burger\", \"sprite\"\n","\n","`### Response:`\n","\n","\"burger\" because all other three are soft drinks.\n","\n","### **Phi-3 Prompt Template**\n","`<|user|>`\n","Identify the odd one out.\n","\"coke\", \"pepsi\", \"burger\", \"fanta\"\n","\n","`<|assistant|>`\n","\"burger\" because all other three are soft drinks."],"metadata":{"id":"p2A79mbcoX_t"}},{"cell_type":"code","source":["def format_input(entry):\n","  instruction_text = (\n","      f\"Below is an instruction that describes a task.\"\n","      f\"Write a response that appropriately completes the request.\"\n","      f\"\\n\\n Instruction:\\n{entry['instruction']}\"\n","  )\n","  input_text = f\"\\n\\n Input:\\n{entry['input']}\" if entry['input'] else \"\"\n","  return instruction_text + input_text"],"metadata":{"id":"bxaJdpxbpdoh","executionInfo":{"status":"ok","timestamp":1736844735348,"user_tz":-345,"elapsed":9,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["model_input = format_input(data[0])"],"metadata":{"id":"jbN9clv5os19","executionInfo":{"status":"ok","timestamp":1736844735348,"user_tz":-345,"elapsed":8,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["print(model_input)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0K4mK08Rq92Q","executionInfo":{"status":"ok","timestamp":1736844735348,"user_tz":-345,"elapsed":8,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"91562d9e-eafe-4030-e7df-62fa1f4b92c6"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Below is an instruction that describes a task.Write a response that appropriately completes the request.\n","\n"," Instruction:\n","Evaluate the following phrase by transforming it into the spelling given.\n","\n"," Input:\n","freind --> friend\n"]}]},{"cell_type":"code","source":["desired_response = f\"\\n\\n Response: \\n{data[0]['output']}\"\n","print(desired_response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Onvg1eRVrF3j","executionInfo":{"status":"ok","timestamp":1736844735348,"user_tz":-345,"elapsed":7,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"e949fb5c-4810-4caa-ee29-efa83ef4ad7a"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n"," Response: \n","The spelling of the given phrase \"freind\" is incorrect, the correct spelling is \"friend\".\n"]}]},{"cell_type":"code","source":["print(model_input + desired_response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s8zKq3VdrSIJ","executionInfo":{"status":"ok","timestamp":1736844735348,"user_tz":-345,"elapsed":6,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"ef03e7b9-7ce1-484c-b46b-0cb630113a74"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Below is an instruction that describes a task.Write a response that appropriately completes the request.\n","\n"," Instruction:\n","Evaluate the following phrase by transforming it into the spelling given.\n","\n"," Input:\n","freind --> friend\n","\n"," Response: \n","The spelling of the given phrase \"freind\" is incorrect, the correct spelling is \"friend\".\n"]}]},{"cell_type":"markdown","source":["### Train Test Val"],"metadata":{"id":"D12Njj4nrk09"}},{"cell_type":"code","source":["# data preparation"],"metadata":{"id":"RLDGTjV-sKUq","executionInfo":{"status":"ok","timestamp":1736844735348,"user_tz":-345,"elapsed":5,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["train_portion = int(len(data) * 0.85)\n","test_portion = int(len(data) * 0.1)\n","val_portion = len(data) - train_portion - test_portion"],"metadata":{"id":"cBmXwo8lrmln","executionInfo":{"status":"ok","timestamp":1736844735348,"user_tz":-345,"elapsed":4,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["train_data = data[:train_portion]\n","test_data = data[train_portion:train_portion+test_portion]\n","val_data = data[-val_portion:]"],"metadata":{"id":"2stpOmK6ryRg","executionInfo":{"status":"ok","timestamp":1736844735348,"user_tz":-345,"elapsed":4,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["print(\"Training set length:\", len(train_data))\n","print(\"Validation set length:\", len(val_data))\n","print(\"Test set length:\", len(test_data))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2pIl1lnXr-FE","executionInfo":{"status":"ok","timestamp":1736844735348,"user_tz":-345,"elapsed":4,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"80961a4b-1b65-41d2-a0e0-9b9586ef01aa"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Training set length: 935\n","Validation set length: 55\n","Test set length: 110\n"]}]},{"cell_type":"markdown","source":["### Preparing Train Data"],"metadata":{"id":"0Vxr5_c3sega"}},{"cell_type":"code","source":["import torch\n","from torch.utils.data import Dataset\n","\n","class InstructionDataset(Dataset):\n","  def __init__(self, data, tokenizer):\n","    self.data = data\n","\n","    self.encoded_texts = []\n","    for entry in data:\n","      prompt = format_input(entry)\n","      response = f\"\\n\\n Response:\\n{entry['output']}\"\n","      prompt_template = prompt + response\n","      self.encoded_texts.append(\n","          tokenizer.encode(prompt_template)\n","      )\n","\n","  def __getitem__(self, index: int):\n","    return self.encoded_texts[index]\n","\n","  def __len__(self):\n","    return len(self.data)"],"metadata":{"id":"2kFMeQ1LsgIJ","executionInfo":{"status":"ok","timestamp":1736844738385,"user_tz":-345,"elapsed":3040,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# getting the byte pair encoding tokenizer\n","!pip install tiktoken"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KvzXtmpkt6On","executionInfo":{"status":"ok","timestamp":1736844741176,"user_tz":-345,"elapsed":2793,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"7d517c36-3ca8-4d0e-eda2-99a86acf5f9b"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tiktoken\n","  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.11.6)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.32.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.12.14)\n","Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tiktoken\n","Successfully installed tiktoken-0.8.0\n"]}]},{"cell_type":"code","source":["import tiktoken\n","tokenizer = tiktoken.get_encoding(\"gpt2\")\n","\n","tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1OKi1Z1ruAYO","executionInfo":{"status":"ok","timestamp":1736844747597,"user_tz":-345,"elapsed":6423,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"2fb27c16-1cb5-4178-8358-e0522b8ea9cc"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[50256]"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["### Custom Colate Function for efficient dataloading"],"metadata":{"id":"b2zkclHbuZfX"}},{"cell_type":"code","source":["[[1,2],[3,4],[5,6]][:-1] # except the last one"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KS3uudO2vh7c","executionInfo":{"status":"ok","timestamp":1736844747597,"user_tz":-345,"elapsed":17,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"d796a0ac-c295-404b-ba17-071256373dd0"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[1, 2], [3, 4]]"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["def custom_collate_1(\n","    batch,\n","    pad_token_id=50256,\n","    device=\"cpu\"\n","):\n","  batch_max_seq_len = max(len(item) + 1 for item in batch) # adding extra pad token which will be relevant in later code\n","  input_lst = []\n","\n","  for item in batch:\n","    new_item = item.copy()\n","    new_item += [pad_token_id] # <|endoftext|> token at last\n","    padded = (\n","        new_item + [pad_token_id] * (batch_max_seq_len - len(new_item))\n","    )\n","    inputs = torch.tensor(padded[:-1]) # remove the last extra padding token\n","    input_lst.append(inputs)\n","\n","  inputs_tensor = torch.stack(input_lst).to(device)\n","  return inputs_tensor"],"metadata":{"id":"VRkZMQVGudGe","executionInfo":{"status":"ok","timestamp":1736844747597,"user_tz":-345,"elapsed":16,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["inputs_1 = [0, 1, 2, 3, 4]\n","inputs_2 = [5, 6]\n","inputs_3 = [7, 8, 9]\n","\n","batch = (\n","    inputs_1,\n","    inputs_2,\n","    inputs_3\n",")\n","\n","print(custom_collate_1(batch))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zDFQ7TnPwj7E","executionInfo":{"status":"ok","timestamp":1736844747597,"user_tz":-345,"elapsed":16,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"e701314f-2eec-4b14-cc84-d456e1c5fabb"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[    0,     1,     2,     3,     4],\n","        [    5,     6, 50256, 50256, 50256],\n","        [    7,     8,     9, 50256, 50256]])\n"]}]},{"cell_type":"markdown","source":["Similar to the pretraining LLM the targets are the inputs shifted by 1 position to the right so the LLM learns to predict the next token"],"metadata":{"id":"9l1pGH8TxDm4"}},{"cell_type":"code","source":["def custom_collate(batch: list, pad_token_id = 50256, device = \"cpu\"):\n","  batch_max_seq_len = max(len(item) + 1 for item in batch)\n","  inputs_list = []\n","  targets_list = []\n","\n","  for item in batch:\n","    new_item = item.copy()\n","    new_item += [pad_token_id]\n","    padded = (\n","        new_item + [pad_token_id] * (batch_max_seq_len - len(new_item))\n","    )\n","    inputs = torch.tensor(padded[:-1])\n","    targets = torch.tensor(padded[1:])\n","    inputs_list.append(inputs)\n","    targets_list.append(targets)\n","\n","  inputs_tensor = torch.stack(inputs_list).to(device)\n","  targets_tensor = torch.stack(targets_list).to(device)\n","  return inputs_tensor, targets_tensor"],"metadata":{"id":"dZ_zUuZCxKyR","executionInfo":{"status":"ok","timestamp":1736844747597,"user_tz":-345,"elapsed":15,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["\n","inputs, targets = custom_collate(batch)\n","print(inputs)\n","print(targets)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c3tZTFkG1UqY","executionInfo":{"status":"ok","timestamp":1736844747597,"user_tz":-345,"elapsed":14,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"b04f0b57-4bcb-4d12-c62c-bd239f3f81e7"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[    0,     1,     2,     3,     4],\n","        [    5,     6, 50256, 50256, 50256],\n","        [    7,     8,     9, 50256, 50256]])\n","tensor([[    1,     2,     3,     4, 50256],\n","        [    6, 50256, 50256, 50256, 50256],\n","        [    8,     9, 50256, 50256, 50256]])\n"]}]},{"cell_type":"markdown","source":["we can add `**ignore_index**` value to replace all padding token IDS with a new value, the purpose of this token is to mask the instruction token later while error calculation"],"metadata":{"id":"g-PUne6B1a-x"}},{"cell_type":"markdown","source":["we can also have `allowed_max_length` in case we want to limit the length of the samples, this will be useful if we plan to work with our own datasets that are longer than the 1024 token context"],"metadata":{"id":"fVUnvu8b3TOf"}},{"cell_type":"code","source":["def custom_collate_fn(\n","    batch,\n","    pad_token_id=50256,\n","    ignore_index=-100,\n","    allowed_max_length=None,\n","    device=\"cpu\"\n","):\n","    batch_max_seq_len = max(len(item) + 1 for item in batch)\n","    inputs_list = []\n","    targets_list = []\n","\n","    for item in batch:\n","        new_item = item.copy()\n","        new_item += [pad_token_id]\n","        padded = (\n","            new_item\n","            + [pad_token_id] * (batch_max_seq_len - len(new_item))\n","        )\n","        inputs = torch.tensor(padded[:-1])\n","        targets = torch.tensor(padded[1:])\n","\n","        mask = targets == pad_token_id\n","        indices = torch.nonzero(mask).squeeze()\n","        if indices.numel() > 1:\n","            targets[indices[1:]] = ignore_index # after the first pad_token replace all with -100\n","\n","        if allowed_max_length is not None:\n","          inputs = inputs[:allowed_max_length]\n","          targets = targets[:allowed_max_length]\n","\n","        inputs_list.append(inputs)\n","        targets_list.append(targets)\n","\n","    inputs_tensor = torch.stack(inputs_list).to(device)\n","    targets_tensor = torch.stack(targets_list).to(device)\n","    return inputs_tensor, targets_tensor"],"metadata":{"id":"i_Ga09Gn3Fcx","executionInfo":{"status":"ok","timestamp":1736844747597,"user_tz":-345,"elapsed":13,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["inputs, targets = custom_collate_fn(batch)\n","print(inputs)\n","print(targets)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xWwWAXpI5ulW","executionInfo":{"status":"ok","timestamp":1736844747597,"user_tz":-345,"elapsed":13,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"20dcd76c-3c66-41cf-8efd-09440f7903fc"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[    0,     1,     2,     3,     4],\n","        [    5,     6, 50256, 50256, 50256],\n","        [    7,     8,     9, 50256, 50256]])\n","tensor([[    1,     2,     3,     4, 50256],\n","        [    6, 50256,  -100,  -100,  -100],\n","        [    8,     9, 50256,  -100,  -100]])\n"]}]},{"cell_type":"markdown","source":["### purpose of -100"],"metadata":{"id":"Xsb_NzpP6YFE"}},{"cell_type":"code","source":["logits_1 = torch.tensor(\n","    [[-1.0, 1.0],  # 1st training example\n","     [-0.5, 1.5]]  # 2nd training example\n",")\n","preds_1 = torch.softmax(logits_1, dim=1)\n","\n","targets_1 = torch.tensor([0, 1])\n","\n","\n","loss_1 = torch.nn.functional.cross_entropy(logits_1, targets_1)\n","print(loss_1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cOF8vqYf6ZsC","executionInfo":{"status":"ok","timestamp":1736844747597,"user_tz":-345,"elapsed":12,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"efc7b9c5-b5fd-40e7-a291-fd0e00d06419"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(1.1269)\n"]}]},{"cell_type":"code","source":["range(len(targets_1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h5g4lXBN7CEf","executionInfo":{"status":"ok","timestamp":1736844747597,"user_tz":-345,"elapsed":11,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"998255a6-f1bd-43ad-c602-df75297dce3a"},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["range(0, 2)"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["preds_1[[0, 1], [0, 1]]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F1lRgh2J7LDB","executionInfo":{"status":"ok","timestamp":1736844747597,"user_tz":-345,"elapsed":9,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"551ff1bd-b795-477b-ff0a-24bde867dfe7"},"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.1192, 0.8808])"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["preds_1[range(len(targets_1)), targets_1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rt3Kvl0m7ASf","executionInfo":{"status":"ok","timestamp":1736844747597,"user_tz":-345,"elapsed":8,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"e91aa21e-f4da-4791-f21c-471f0c02d61d"},"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.1192, 0.8808])"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["log_likelihood = torch.log(preds_1[range(len(targets_1)), targets_1])\n","error = -log_likelihood.mean()\n","print(error)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PjTyRuR06rLu","executionInfo":{"status":"ok","timestamp":1736844747597,"user_tz":-345,"elapsed":7,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"02c5ee77-9762-4037-c984-e3cab4260814"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(1.1269)\n"]}]},{"cell_type":"markdown","source":["adding one more training example"],"metadata":{"id":"fbFZ_jlY7fTb"}},{"cell_type":"code","source":["logits_2 = torch.tensor(\n","    [[-1.0, 1.0],\n","     [-0.5, 1.5],\n","     [-0.5, 1.5]]  # New 3rd training example\n",")\n","targets_2 = torch.tensor([0, 1, 1])\n","\n","loss_2 = torch.nn.functional.cross_entropy(logits_2, targets_2)\n","print(loss_2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8akAbvtR7hm6","executionInfo":{"status":"ok","timestamp":1736844747597,"user_tz":-345,"elapsed":6,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"15bf244b-bee9-4f70-e928-b94d7b8b4731"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(0.7936)\n"]}]},{"cell_type":"markdown","source":["If we replace the class label of one of the examples with -100"],"metadata":{"id":"bPkXTVFR7o21"}},{"cell_type":"code","source":["targets_3 = torch.tensor([0, 1, -100])\n","\n","loss_3 = torch.nn.functional.cross_entropy(logits_2, targets_3)\n","print(loss_3)\n","print(\"loss_1 == loss_3:\", loss_1 == loss_3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n4AYuVMU7mlT","executionInfo":{"status":"ok","timestamp":1736844747597,"user_tz":-345,"elapsed":5,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"95a13efc-3414-4e5d-fd5c-de194702b99f"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(1.1269)\n","loss_1 == loss_3: tensor(True)\n"]}]},{"cell_type":"markdown","source":["By this it means the cross entropy loss function ignored the training example with the -100 label.\n","\n","By default `cross entropy` has **ignore_index=-100** set which ignore the corresponding label -100 while generalizing.\n","\n","Using this -100 ignore index we can ignore the additional end of text (padding) tokens in the batches that we used to pad the training examples to equal length.\n","\n","But we dont want to ignore the fist instance of the pad token because we can use it to identify when the response end so that we can stop the inference.\n","\n","In practice it is also common to mask out the target token IDs that correspond to the instruction prompt"],"metadata":{"id":"ihHQ-pww8A4R"}},{"cell_type":"markdown","source":["### Creating data loaders for an instruction dataset"],"metadata":{"id":"gH4IBFHA8xJO"}},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"uF4U6asw8s8-","executionInfo":{"status":"ok","timestamp":1736844747598,"user_tz":-345,"elapsed":5,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NnW842pd9Akn","executionInfo":{"status":"ok","timestamp":1736844748203,"user_tz":-345,"elapsed":610,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"cc91400b-3fd3-4a92-cd02-d0c07eabb109"},"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["from torch.utils.data import DataLoader\n","\n","num_workers = 0\n","batch_size = 8\n","\n","train_dataset = InstructionDataset(train_data, tokenizer)\n","train_loader = DataLoader(\n","    dataset=train_dataset,\n","    batch_size=batch_size,\n","    collate_fn=custom_collate_fn,\n","    shuffle=True,\n","    drop_last=True,\n","    num_workers=num_workers\n",")"],"metadata":{"id":"pe5ZzO7w9CBq","executionInfo":{"status":"ok","timestamp":1736844748203,"user_tz":-345,"elapsed":4,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["val_dataset = InstructionDataset(val_data, tokenizer)\n","val_loader = DataLoader(\n","    val_dataset,\n","    batch_size=batch_size,\n","    collate_fn=custom_collate_fn,\n","    shuffle=False,\n","    drop_last=False,\n","    num_workers=num_workers\n",")\n","\n","test_dataset = InstructionDataset(test_data, tokenizer)\n","test_loader = DataLoader(\n","    test_dataset,\n","    batch_size=batch_size,\n","    collate_fn=custom_collate_fn,\n","    shuffle=False,\n","    drop_last=False,\n","    num_workers=num_workers\n",")"],"metadata":{"id":"SeJgeSfr9aPl","executionInfo":{"status":"ok","timestamp":1736844748203,"user_tz":-345,"elapsed":3,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["print(\"Train loader:\")\n","for inputs, targets in train_loader:\n","    print(inputs.shape, targets.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZE9t7rJ19lKu","executionInfo":{"status":"ok","timestamp":1736844748930,"user_tz":-345,"elapsed":730,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"6b1594c3-6649-4e83-b939-760d8fdc6618"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Train loader:\n","torch.Size([8, 66]) torch.Size([8, 66])\n","torch.Size([8, 64]) torch.Size([8, 64])\n","torch.Size([8, 85]) torch.Size([8, 85])\n","torch.Size([8, 61]) torch.Size([8, 61])\n","torch.Size([8, 67]) torch.Size([8, 67])\n","torch.Size([8, 60]) torch.Size([8, 60])\n","torch.Size([8, 59]) torch.Size([8, 59])\n","torch.Size([8, 87]) torch.Size([8, 87])\n","torch.Size([8, 64]) torch.Size([8, 64])\n","torch.Size([8, 79]) torch.Size([8, 79])\n","torch.Size([8, 53]) torch.Size([8, 53])\n","torch.Size([8, 57]) torch.Size([8, 57])\n","torch.Size([8, 60]) torch.Size([8, 60])\n","torch.Size([8, 73]) torch.Size([8, 73])\n","torch.Size([8, 71]) torch.Size([8, 71])\n","torch.Size([8, 84]) torch.Size([8, 84])\n","torch.Size([8, 53]) torch.Size([8, 53])\n","torch.Size([8, 85]) torch.Size([8, 85])\n","torch.Size([8, 62]) torch.Size([8, 62])\n","torch.Size([8, 60]) torch.Size([8, 60])\n","torch.Size([8, 64]) torch.Size([8, 64])\n","torch.Size([8, 59]) torch.Size([8, 59])\n","torch.Size([8, 83]) torch.Size([8, 83])\n","torch.Size([8, 65]) torch.Size([8, 65])\n","torch.Size([8, 58]) torch.Size([8, 58])\n","torch.Size([8, 60]) torch.Size([8, 60])\n","torch.Size([8, 76]) torch.Size([8, 76])\n","torch.Size([8, 64]) torch.Size([8, 64])\n","torch.Size([8, 72]) torch.Size([8, 72])\n","torch.Size([8, 70]) torch.Size([8, 70])\n","torch.Size([8, 63]) torch.Size([8, 63])\n","torch.Size([8, 70]) torch.Size([8, 70])\n","torch.Size([8, 76]) torch.Size([8, 76])\n","torch.Size([8, 57]) torch.Size([8, 57])\n","torch.Size([8, 63]) torch.Size([8, 63])\n","torch.Size([8, 56]) torch.Size([8, 56])\n","torch.Size([8, 67]) torch.Size([8, 67])\n","torch.Size([8, 67]) torch.Size([8, 67])\n","torch.Size([8, 55]) torch.Size([8, 55])\n","torch.Size([8, 75]) torch.Size([8, 75])\n","torch.Size([8, 72]) torch.Size([8, 72])\n","torch.Size([8, 67]) torch.Size([8, 67])\n","torch.Size([8, 79]) torch.Size([8, 79])\n","torch.Size([8, 69]) torch.Size([8, 69])\n","torch.Size([8, 53]) torch.Size([8, 53])\n","torch.Size([8, 59]) torch.Size([8, 59])\n","torch.Size([8, 59]) torch.Size([8, 59])\n","torch.Size([8, 58]) torch.Size([8, 58])\n","torch.Size([8, 58]) torch.Size([8, 58])\n","torch.Size([8, 67]) torch.Size([8, 67])\n","torch.Size([8, 55]) torch.Size([8, 55])\n","torch.Size([8, 64]) torch.Size([8, 64])\n","torch.Size([8, 65]) torch.Size([8, 65])\n","torch.Size([8, 62]) torch.Size([8, 62])\n","torch.Size([8, 64]) torch.Size([8, 64])\n","torch.Size([8, 60]) torch.Size([8, 60])\n","torch.Size([8, 67]) torch.Size([8, 67])\n","torch.Size([8, 56]) torch.Size([8, 56])\n","torch.Size([8, 69]) torch.Size([8, 69])\n","torch.Size([8, 61]) torch.Size([8, 61])\n","torch.Size([8, 63]) torch.Size([8, 63])\n","torch.Size([8, 72]) torch.Size([8, 72])\n","torch.Size([8, 63]) torch.Size([8, 63])\n","torch.Size([8, 58]) torch.Size([8, 58])\n","torch.Size([8, 59]) torch.Size([8, 59])\n","torch.Size([8, 54]) torch.Size([8, 54])\n","torch.Size([8, 55]) torch.Size([8, 55])\n","torch.Size([8, 57]) torch.Size([8, 57])\n","torch.Size([8, 59]) torch.Size([8, 59])\n","torch.Size([8, 72]) torch.Size([8, 72])\n","torch.Size([8, 68]) torch.Size([8, 68])\n","torch.Size([8, 56]) torch.Size([8, 56])\n","torch.Size([8, 71]) torch.Size([8, 71])\n","torch.Size([8, 53]) torch.Size([8, 53])\n","torch.Size([8, 58]) torch.Size([8, 58])\n","torch.Size([8, 62]) torch.Size([8, 62])\n","torch.Size([8, 66]) torch.Size([8, 66])\n","torch.Size([8, 70]) torch.Size([8, 70])\n","torch.Size([8, 63]) torch.Size([8, 63])\n","torch.Size([8, 57]) torch.Size([8, 57])\n","torch.Size([8, 54]) torch.Size([8, 54])\n","torch.Size([8, 67]) torch.Size([8, 67])\n","torch.Size([8, 69]) torch.Size([8, 69])\n","torch.Size([8, 62]) torch.Size([8, 62])\n","torch.Size([8, 53]) torch.Size([8, 53])\n","torch.Size([8, 58]) torch.Size([8, 58])\n","torch.Size([8, 56]) torch.Size([8, 56])\n","torch.Size([8, 60]) torch.Size([8, 60])\n","torch.Size([8, 58]) torch.Size([8, 58])\n","torch.Size([8, 68]) torch.Size([8, 68])\n","torch.Size([8, 70]) torch.Size([8, 70])\n","torch.Size([8, 79]) torch.Size([8, 79])\n","torch.Size([8, 56]) torch.Size([8, 56])\n","torch.Size([8, 59]) torch.Size([8, 59])\n","torch.Size([8, 58]) torch.Size([8, 58])\n","torch.Size([8, 74]) torch.Size([8, 74])\n","torch.Size([8, 60]) torch.Size([8, 60])\n","torch.Size([8, 68]) torch.Size([8, 68])\n","torch.Size([8, 76]) torch.Size([8, 76])\n","torch.Size([8, 68]) torch.Size([8, 68])\n","torch.Size([8, 79]) torch.Size([8, 79])\n","torch.Size([8, 55]) torch.Size([8, 55])\n","torch.Size([8, 77]) torch.Size([8, 77])\n","torch.Size([8, 54]) torch.Size([8, 54])\n","torch.Size([8, 77]) torch.Size([8, 77])\n","torch.Size([8, 59]) torch.Size([8, 59])\n","torch.Size([8, 59]) torch.Size([8, 59])\n","torch.Size([8, 62]) torch.Size([8, 62])\n","torch.Size([8, 76]) torch.Size([8, 76])\n","torch.Size([8, 54]) torch.Size([8, 54])\n","torch.Size([8, 85]) torch.Size([8, 85])\n","torch.Size([8, 55]) torch.Size([8, 55])\n","torch.Size([8, 65]) torch.Size([8, 65])\n","torch.Size([8, 62]) torch.Size([8, 62])\n","torch.Size([8, 59]) torch.Size([8, 59])\n","torch.Size([8, 64]) torch.Size([8, 64])\n"]}]},{"cell_type":"markdown","source":["Here batch size is 8 and each batch size has equal sequence length with padding in it"],"metadata":{"id":"QxUN-zvx97_f"}},{"cell_type":"code","source":["# to verify it\n","inputs[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"785PffEE-AN0","executionInfo":{"status":"ok","timestamp":1736844748931,"user_tz":-345,"elapsed":5,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"4c9d60a1-f339-4da6-9767-681af699e394"},"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 16594,\n","          257,  2882,   326, 20431, 32543,   262,  2581,    13,   628, 46486,\n","           25,   198,  9487,  1958,   262,  1708,   656, 13701,    11,  4695,\n","           11,   290, 21782,    13,   628, 23412,    25,   198, 15783, 34544,\n","           11,  7931,    11, 42651,   628, 18261,    25,   198, 26979,  1136,\n","         2977,    25,  2806, 34544,   198,  9171,   874,    25,  7931,   198,\n","        35320,   874,    25, 42651])"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["targets[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bl4GL6eh-DA_","executionInfo":{"status":"ok","timestamp":1736844748931,"user_tz":-345,"elapsed":3,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"5c6b9e00-7d93-4fd2-9a52-a197cbe68894"},"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([  318,   281, 12064,   326,  8477,   257,  4876,    13, 16594,   257,\n","         2882,   326, 20431, 32543,   262,  2581,    13,   628, 46486,    25,\n","          198,  9487,  1958,   262,  1708,   656, 13701,    11,  4695,    11,\n","          290, 21782,    13,   628, 23412,    25,   198, 15783, 34544,    11,\n","         7931,    11, 42651,   628, 18261,    25,   198, 26979,  1136,  2977,\n","           25,  2806, 34544,   198,  9171,   874,    25,  7931,   198, 35320,\n","          874,    25, 42651, 50256])"]},"metadata":{},"execution_count":37}]},{"cell_type":"markdown","source":["## Loading a GPT2 Model"],"metadata":{"id":"bQcNQ7EJ-G3f"}},{"cell_type":"code","source":["BASE_CONFIG = {\n","    \"vocab_size\": 50257,     # Vocabulary size\n","    \"context_length\": 1024,  # Context length\n","    \"drop_rate\": 0.0,        # Dropout rate\n","    \"qkv_bias\": True         # Query-key-value bias\n","}\n","\n","model_configs = {\n","    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n","    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n","    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n","    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n","}\n","\n","CHOOSE_MODEL = \"gpt2-medium (355M)\"\n","BASE_CONFIG.update(model_configs[CHOOSE_MODEL])"],"metadata":{"id":"7EfKGinc-IrG","executionInfo":{"status":"ok","timestamp":1736844748931,"user_tz":-345,"elapsed":2,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["import os\n","import urllib.request\n","\n","import json\n","import numpy as np\n","import tensorflow as tf\n","from tqdm import tqdm\n","\n","\n","def download_and_load_gpt2(model_size, models_dir):\n","    # Validate model size\n","    allowed_sizes = (\"124M\", \"355M\", \"774M\", \"1558M\")\n","    if model_size not in allowed_sizes:\n","        raise ValueError(f\"Model size not in {allowed_sizes}\")\n","\n","    # Define paths\n","    model_dir = os.path.join(models_dir, model_size)\n","    base_url = \"https://openaipublic.blob.core.windows.net/gpt-2/models\"\n","    backup_base_url = \"https://f001.backblazeb2.com/file/LLMs-from-scratch/gpt2\"\n","    filenames = [\n","        \"checkpoint\", \"encoder.json\", \"hparams.json\",\n","        \"model.ckpt.data-00000-of-00001\", \"model.ckpt.index\",\n","        \"model.ckpt.meta\", \"vocab.bpe\"\n","    ]\n","\n","    # Download files\n","    os.makedirs(model_dir, exist_ok=True)\n","    for filename in filenames:\n","        file_url = os.path.join(base_url, model_size, filename)\n","        backup_url = os.path.join(backup_base_url, model_size, filename)\n","        file_path = os.path.join(model_dir, filename)\n","        download_file(file_url, file_path, backup_url)\n","\n","    # Load settings and params\n","    tf_ckpt_path = tf.train.latest_checkpoint(model_dir)\n","    settings = json.load(open(os.path.join(model_dir, \"hparams.json\")))\n","    params = load_gpt2_params_from_tf_ckpt(tf_ckpt_path, settings)\n","\n","    return settings, params\n","\n","\n","def download_file(url, destination, backup_url=None):\n","    def _attempt_download(download_url):\n","        with urllib.request.urlopen(download_url) as response:\n","            # Get the total file size from headers, defaulting to 0 if not present\n","            file_size = int(response.headers.get(\"Content-Length\", 0))\n","\n","            # Check if file exists and has the same size\n","            if os.path.exists(destination):\n","                file_size_local = os.path.getsize(destination)\n","                if file_size == file_size_local:\n","                    print(f\"File already exists and is up-to-date: {destination}\")\n","                    return True  # Indicate success without re-downloading\n","\n","            block_size = 1024  # 1 Kilobyte\n","\n","            # Initialize the progress bar with total file size\n","            progress_bar_description = os.path.basename(download_url)\n","            with tqdm(total=file_size, unit=\"iB\", unit_scale=True, desc=progress_bar_description) as progress_bar:\n","                with open(destination, \"wb\") as file:\n","                    while True:\n","                        chunk = response.read(block_size)\n","                        if not chunk:\n","                            break\n","                        file.write(chunk)\n","                        progress_bar.update(len(chunk))\n","            return True\n","\n","    try:\n","        if _attempt_download(url):\n","            return\n","    except (urllib.error.HTTPError, urllib.error.URLError):\n","        if backup_url is not None:\n","            print(f\"Primary URL ({url}) failed. Attempting backup URL: {backup_url}\")\n","            try:\n","                if _attempt_download(backup_url):\n","                    return\n","            except urllib.error.HTTPError:\n","                pass\n","\n","        # If we reach here, both attempts have failed\n","        error_message = (\n","            f\"Failed to download from both primary URL ({url})\"\n","            f\"{' and backup URL (' + backup_url + ')' if backup_url else ''}.\"\n","            \"\\nCheck your internet connection or the file availability.\\n\"\n","            \"For help, visit: https://github.com/rasbt/LLMs-from-scratch/discussions/273\"\n","        )\n","        print(error_message)\n","    except Exception as e:\n","        print(f\"An unexpected error occurred: {e}\")\n","\n","\n","def load_gpt2_params_from_tf_ckpt(ckpt_path, settings):\n","    # Initialize parameters dictionary with empty blocks for each layer\n","    params = {\"blocks\": [{} for _ in range(settings[\"n_layer\"])]}\n","\n","    # Iterate over each variable in the checkpoint\n","    for name, _ in tf.train.list_variables(ckpt_path):\n","        # Load the variable and remove singleton dimensions\n","        variable_array = np.squeeze(tf.train.load_variable(ckpt_path, name))\n","\n","        # Process the variable name to extract relevant parts\n","        variable_name_parts = name.split(\"/\")[1:]  # Skip the 'model/' prefix\n","\n","        # Identify the target dictionary for the variable\n","        target_dict = params\n","        if variable_name_parts[0].startswith(\"h\"):\n","            layer_number = int(variable_name_parts[0][1:])\n","            target_dict = params[\"blocks\"][layer_number]\n","\n","        # Recursively access or create nested dictionaries\n","        for key in variable_name_parts[1:-1]:\n","            target_dict = target_dict.setdefault(key, {})\n","\n","        # Assign the variable array to the last key\n","        last_key = variable_name_parts[-1]\n","        target_dict[last_key] = variable_array\n","\n","    return params"],"metadata":{"id":"4qKK_vQM-YD7","executionInfo":{"status":"ok","timestamp":1736844754612,"user_tz":-345,"elapsed":5683,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","from matplotlib.ticker import MaxNLocator\n","import numpy as np\n","import tiktoken\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","\n","class GPTDatasetV1(Dataset):\n","    def __init__(self, txt, tokenizer, max_length, stride):\n","        self.tokenizer = tokenizer\n","        self.input_ids = []\n","        self.target_ids = []\n","\n","        # Tokenize the entire text\n","        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n","\n","        # Use a sliding window to chunk the book into overlapping sequences of max_length\n","        for i in range(0, len(token_ids) - max_length, stride):\n","            input_chunk = token_ids[i:i + max_length]\n","            target_chunk = token_ids[i + 1: i + max_length + 1]\n","            self.input_ids.append(torch.tensor(input_chunk))\n","            self.target_ids.append(torch.tensor(target_chunk))\n","\n","    def __len__(self):\n","        return len(self.input_ids)\n","\n","    def __getitem__(self, idx):\n","        return self.input_ids[idx], self.target_ids[idx]\n","\n","\n","def create_dataloader_v1(txt, batch_size=4, max_length=256,\n","                         stride=128, shuffle=True, drop_last=True, num_workers=0):\n","    # Initialize the tokenizer\n","    tokenizer = tiktoken.get_encoding(\"gpt2\")\n","\n","    # Create dataset\n","    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n","\n","    # Create dataloader\n","    dataloader = DataLoader(\n","        dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers)\n","\n","    return dataloader\n","\n","class MultiHeadAttention(nn.Module):\n","    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n","        super().__init__()\n","        assert d_out % num_heads == 0, \"d_out must be divisible by n_heads\"\n","\n","        self.d_out = d_out\n","        self.num_heads = num_heads\n","        self.head_dim = d_out // num_heads  # Reduce the projection dim to match desired output dim\n","\n","        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n","        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n","        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n","        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n","        self.dropout = nn.Dropout(dropout)\n","        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1))\n","\n","    def forward(self, x):\n","        b, num_tokens, d_in = x.shape\n","\n","        keys = self.W_key(x)  # Shape: (b, num_tokens, d_out)\n","        queries = self.W_query(x)\n","        values = self.W_value(x)\n","\n","        # We implicitly split the matrix by adding a `num_heads` dimension\n","        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n","        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n","        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n","        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n","\n","        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n","        keys = keys.transpose(1, 2)\n","        queries = queries.transpose(1, 2)\n","        values = values.transpose(1, 2)\n","\n","        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n","        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n","\n","        # Original mask truncated to the number of tokens and converted to boolean\n","        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n","\n","        # Use the mask to fill attention scores\n","        attn_scores.masked_fill_(mask_bool, -torch.inf)\n","\n","        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n","        attn_weights = self.dropout(attn_weights)\n","\n","        # Shape: (b, num_tokens, num_heads, head_dim)\n","        context_vec = (attn_weights @ values).transpose(1, 2)\n","\n","        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n","        context_vec = context_vec.reshape(b, num_tokens, self.d_out)\n","        context_vec = self.out_proj(context_vec)  # optional projection\n","\n","        return context_vec\n","\n","class LayerNorm(nn.Module):\n","    def __init__(self, emb_dim):\n","        super().__init__()\n","        self.eps = 1e-5\n","        self.scale = nn.Parameter(torch.ones(emb_dim))\n","        self.shift = nn.Parameter(torch.zeros(emb_dim))\n","\n","    def forward(self, x):\n","        mean = x.mean(dim=-1, keepdim=True)\n","        var = x.var(dim=-1, keepdim=True, unbiased=False)\n","        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n","        return self.scale * norm_x + self.shift\n","\n","\n","class GELU(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","    def forward(self, x):\n","        return 0.5 * x * (1 + torch.tanh(\n","            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n","            (x + 0.044715 * torch.pow(x, 3))\n","        ))\n","\n","\n","class FeedForward(nn.Module):\n","    def __init__(self, cfg):\n","        super().__init__()\n","        self.layers = nn.Sequential(\n","            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n","            GELU(),\n","            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n","        )\n","\n","    def forward(self, x):\n","        return self.layers(x)\n","\n","\n","class TransformerBlock(nn.Module):\n","    def __init__(self, cfg):\n","        super().__init__()\n","        self.att = MultiHeadAttention(\n","            d_in=cfg[\"emb_dim\"],\n","            d_out=cfg[\"emb_dim\"],\n","            context_length=cfg[\"context_length\"],\n","            num_heads=cfg[\"n_heads\"],\n","            dropout=cfg[\"drop_rate\"],\n","            qkv_bias=cfg[\"qkv_bias\"])\n","        self.ff = FeedForward(cfg)\n","        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n","        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n","        self.drop_resid = nn.Dropout(cfg[\"drop_rate\"])\n","\n","    def forward(self, x):\n","        # Shortcut connection for attention block\n","        shortcut = x\n","        x = self.norm1(x)\n","        x = self.att(x)   # Shape [batch_size, num_tokens, emb_size]\n","        x = self.drop_resid(x)\n","        x = x + shortcut  # Add the original input back\n","\n","        # Shortcut connection for feed-forward block\n","        shortcut = x\n","        x = self.norm2(x)\n","        x = self.ff(x)\n","        x = self.drop_resid(x)\n","        x = x + shortcut  # Add the original input back\n","\n","        return x\n","\n","\n","class GPTModel(nn.Module):\n","    def __init__(self, cfg):\n","        super().__init__()\n","        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n","        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n","        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n","\n","        self.trf_blocks = nn.Sequential(\n","            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n","\n","        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n","        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n","\n","    def forward(self, in_idx):\n","        batch_size, seq_len = in_idx.shape\n","        tok_embeds = self.tok_emb(in_idx)\n","        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n","        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n","        x = self.drop_emb(x)\n","        x = self.trf_blocks(x)\n","        x = self.final_norm(x)\n","        logits = self.out_head(x)\n","        return logits\n","\n","\n","def generate_text_simple(model, idx, max_new_tokens, context_size):\n","    # idx is (B, T) array of indices in the current context\n","    for _ in range(max_new_tokens):\n","\n","        # Crop current context if it exceeds the supported context size\n","        # E.g., if LLM supports only 5 tokens, and the context size is 10\n","        # then only the last 5 tokens are used as context\n","        idx_cond = idx[:, -context_size:]\n","\n","        # Get the predictions\n","        with torch.no_grad():\n","            logits = model(idx_cond)\n","\n","        # Focus only on the last time step\n","        # (batch, n_token, vocab_size) becomes (batch, vocab_size)\n","        logits = logits[:, -1, :]\n","\n","        # Get the idx of the vocab entry with the highest logits value\n","        idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch, 1)\n","\n","        # Append sampled index to the running sequence\n","        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n","\n","    return idx\n","\n","def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n","\n","    # For-loop is the same as before: Get logits, and only focus on last time step\n","    for _ in range(max_new_tokens):\n","        idx_cond = idx[:, -context_size:]\n","        with torch.no_grad():\n","            logits = model(idx_cond)\n","        logits = logits[:, -1, :]\n","\n","        # New: Filter logits with top_k sampling\n","        if top_k is not None:\n","            # Keep only top_k values\n","            top_logits, _ = torch.topk(logits, top_k)\n","            min_val = top_logits[:, -1]\n","            logits = torch.where(logits < min_val, torch.tensor(float('-inf')).to(logits.device), logits)\n","\n","        # New: Apply temperature scaling\n","        if temperature > 0.0:\n","            logits = logits / temperature\n","\n","            # Apply softmax to get probabilities\n","            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n","\n","            # Sample from the distribution\n","            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n","\n","        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n","        else:\n","            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n","\n","        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n","            break\n","\n","        # Same as before: append sampled index to the running sequence\n","        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n","\n","    return idx\n","\n","\n","def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n","                       eval_freq, eval_iter, start_context, tokenizer):\n","    # Initialize lists to track losses and tokens seen\n","    train_losses, val_losses, track_tokens_seen = [], [], []\n","    tokens_seen, global_step = 0, -1\n","\n","    # Main training loop\n","    for epoch in range(num_epochs):\n","        model.train()  # Set model to training mode\n","\n","        for input_batch, target_batch in train_loader:\n","            optimizer.zero_grad()  # Reset loss gradients from previous batch iteration\n","            loss = calc_loss_batch(input_batch, target_batch, model, device)\n","            loss.backward()  # Calculate loss gradients\n","            optimizer.step()  # Update model weights using loss gradients\n","            tokens_seen += input_batch.numel()\n","            global_step += 1\n","\n","            # Optional evaluation step\n","            if global_step % eval_freq == 0:\n","                train_loss, val_loss = evaluate_model(\n","                    model, train_loader, val_loader, device, eval_iter)\n","                train_losses.append(train_loss)\n","                val_losses.append(val_loss)\n","                track_tokens_seen.append(tokens_seen)\n","                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n","                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n","\n","        # Print a sample text after each epoch\n","        generate_and_print_sample(\n","            model, tokenizer, device, start_context\n","        )\n","\n","    return train_losses, val_losses, track_tokens_seen\n","\n","\n","def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n","    model.eval()\n","    with torch.no_grad():\n","        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n","        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n","    model.train()\n","    return train_loss, val_loss\n","\n","\n","def generate_and_print_sample(model, tokenizer, device, start_context):\n","    model.eval()\n","    context_size = model.pos_emb.weight.shape[0]\n","    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n","    with torch.no_grad():\n","        token_ids = generate_text_simple(\n","            model=model, idx=encoded,\n","            max_new_tokens=50, context_size=context_size\n","        )\n","        decoded_text = token_ids_to_text(token_ids, tokenizer)\n","        print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n","    model.train()\n","\n","\n","def assign(left, right):\n","    if left.shape != right.shape:\n","        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n","    return torch.nn.Parameter(torch.tensor(right))\n","\n","\n","def load_weights_into_gpt(gpt, params):\n","    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n","    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n","\n","    for b in range(len(params[\"blocks\"])):\n","        q_w, k_w, v_w = np.split(\n","            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n","        gpt.trf_blocks[b].att.W_query.weight = assign(\n","            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n","        gpt.trf_blocks[b].att.W_key.weight = assign(\n","            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n","        gpt.trf_blocks[b].att.W_value.weight = assign(\n","            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n","\n","        q_b, k_b, v_b = np.split(\n","            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n","        gpt.trf_blocks[b].att.W_query.bias = assign(\n","            gpt.trf_blocks[b].att.W_query.bias, q_b)\n","        gpt.trf_blocks[b].att.W_key.bias = assign(\n","            gpt.trf_blocks[b].att.W_key.bias, k_b)\n","        gpt.trf_blocks[b].att.W_value.bias = assign(\n","            gpt.trf_blocks[b].att.W_value.bias, v_b)\n","\n","        gpt.trf_blocks[b].att.out_proj.weight = assign(\n","            gpt.trf_blocks[b].att.out_proj.weight,\n","            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n","        gpt.trf_blocks[b].att.out_proj.bias = assign(\n","            gpt.trf_blocks[b].att.out_proj.bias,\n","            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n","\n","        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n","            gpt.trf_blocks[b].ff.layers[0].weight,\n","            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n","        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n","            gpt.trf_blocks[b].ff.layers[0].bias,\n","            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n","        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n","            gpt.trf_blocks[b].ff.layers[2].weight,\n","            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n","        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n","            gpt.trf_blocks[b].ff.layers[2].bias,\n","            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n","\n","        gpt.trf_blocks[b].norm1.scale = assign(\n","            gpt.trf_blocks[b].norm1.scale,\n","            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n","        gpt.trf_blocks[b].norm1.shift = assign(\n","            gpt.trf_blocks[b].norm1.shift,\n","            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n","        gpt.trf_blocks[b].norm2.scale = assign(\n","            gpt.trf_blocks[b].norm2.scale,\n","            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n","        gpt.trf_blocks[b].norm2.shift = assign(\n","            gpt.trf_blocks[b].norm2.shift,\n","            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n","\n","    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n","    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n","    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n","\n","\n","def text_to_token_ids(text, tokenizer):\n","    encoded = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n","    encoded_tensor = torch.tensor(encoded).unsqueeze(0)  # add batch dimension\n","    return encoded_tensor\n","\n","\n","def token_ids_to_text(token_ids, tokenizer):\n","    flat = token_ids.squeeze(0)  # remove batch dimension\n","    return tokenizer.decode(flat.tolist())\n","\n","\n","def calc_loss_batch(input_batch, target_batch, model, device):\n","    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n","    logits = model(input_batch)\n","    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n","    return loss\n","\n","\n","def calc_loss_loader(data_loader, model, device, num_batches=None):\n","    total_loss = 0.\n","    if len(data_loader) == 0:\n","        return float(\"nan\")\n","    elif num_batches is None:\n","        num_batches = len(data_loader)\n","    else:\n","        # Reduce the number of batches to match the total number of batches in the data loader\n","        # if num_batches exceeds the number of batches in the data loader\n","        num_batches = min(num_batches, len(data_loader))\n","    for i, (input_batch, target_batch) in enumerate(data_loader):\n","        if i < num_batches:\n","            loss = calc_loss_batch(input_batch, target_batch, model, device)\n","            total_loss += loss.item()\n","        else:\n","            break\n","    return total_loss / num_batches\n","\n","\n","def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n","    fig, ax1 = plt.subplots(figsize=(5, 3))\n","\n","    # Plot training and validation loss against epochs\n","    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n","    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n","    ax1.set_xlabel(\"Epochs\")\n","    ax1.set_ylabel(\"Loss\")\n","    ax1.legend(loc=\"upper right\")\n","    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n","\n","    # Create a second x-axis for tokens seen\n","    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n","    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n","    ax2.set_xlabel(\"Tokens seen\")\n","\n","    fig.tight_layout()  # Adjust layout to make room\n","    plt.savefig(\"loss-plot.pdf\")\n","    plt.show()"],"metadata":{"id":"tdc2oKLz-wWi","executionInfo":{"status":"ok","timestamp":1736844754612,"user_tz":-345,"elapsed":2,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n","settings, params = download_and_load_gpt2(\n","    model_size=model_size,\n","    models_dir=\"gpt2\"\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OaC_Auw6-y4v","executionInfo":{"status":"ok","timestamp":1736844966606,"user_tz":-345,"elapsed":211996,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"27685118-1a1d-4e51-ff34-acaf3614919e"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stderr","text":["checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 148kiB/s]\n","encoder.json: 100%|██████████| 1.04M/1.04M [00:01<00:00, 571kiB/s]\n","hparams.json: 100%|██████████| 91.0/91.0 [00:00<00:00, 97.4kiB/s]\n","model.ckpt.data-00000-of-00001: 100%|██████████| 1.42G/1.42G [03:19<00:00, 7.12MiB/s]\n","model.ckpt.index: 100%|██████████| 10.4k/10.4k [00:00<00:00, 8.62MiB/s]\n","model.ckpt.meta: 100%|██████████| 927k/927k [00:01<00:00, 567kiB/s]\n","vocab.bpe: 100%|██████████| 456k/456k [00:01<00:00, 284kiB/s]\n"]}]},{"cell_type":"code","source":["model = GPTModel(BASE_CONFIG)\n","load_weights_into_gpt(model, params)\n","model.eval();"],"metadata":{"id":"cAvYYip9-1P_","executionInfo":{"status":"ok","timestamp":1736844970649,"user_tz":-345,"elapsed":4045,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}}},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":["## Inference before fine tuning"],"metadata":{"id":"3RdzAbvr-_TA"}},{"cell_type":"code","source":["input_text = format_input(val_data[0])\n","print(input_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T-YBkd_A_7EP","executionInfo":{"status":"ok","timestamp":1736844970649,"user_tz":-345,"elapsed":3,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"d041165a-dc2d-44f1-bf4b-f57b6ea6b8f3"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["Below is an instruction that describes a task.Write a response that appropriately completes the request.\n","\n"," Instruction:\n","Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"]}]},{"cell_type":"code","source":["token_ids = generate(\n","    model=model,\n","    idx=text_to_token_ids(input_text, tokenizer),\n","    max_new_tokens=35,\n","    context_size=BASE_CONFIG[\"context_length\"],\n","    eos_id=50256,\n",")\n","generated_text = token_ids_to_text(token_ids, tokenizer)"],"metadata":{"id":"fyuMZ1uX-_-u","executionInfo":{"status":"ok","timestamp":1736845002373,"user_tz":-345,"elapsed":31726,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["generated_text"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"id":"CFlLZT1BAGhF","executionInfo":{"status":"ok","timestamp":1736845002374,"user_tz":-345,"elapsed":8,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"5d8c9410-0986-4dc4-b6a1-186f023fc562"},"execution_count":45,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"Below is an instruction that describes a task.Write a response that appropriately completes the request.\\n\\n Instruction:\\nConvert the active sentence to passive: 'The chef cooks the meal every day.'\\nThe active sentence is the sentence that is being processed. The passive sentence is the sentence that is being processed.\\nThe active sentence is the sentence that is being processed.\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":45}]},{"cell_type":"code","source":["\n","response_text = (\n","    generated_text[len(input_text):]\n","    .replace(\"### Response:\", \"\")\n","    .strip()\n",")\n","print(response_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5L7gkPy2_Hl9","executionInfo":{"status":"ok","timestamp":1736845002374,"user_tz":-345,"elapsed":6,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"771ac73c-4c4b-41dc-a68e-7946a61a5789"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["The active sentence is the sentence that is being processed. The passive sentence is the sentence that is being processed.\n","The active sentence is the sentence that is being processed.\n"]}]},{"cell_type":"markdown","source":["## InstructionFine Tuning"],"metadata":{"id":"sUoHVYUTAPxs"}},{"cell_type":"code","source":["model.to(device)\n","\n","torch.manual_seed(2)\n","\n","with torch.no_grad():\n","    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n","    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n","\n","print(\"Training loss:\", train_loss)\n","print(\"Validation loss:\", val_loss)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z2VhYLXEATLT","executionInfo":{"status":"ok","timestamp":1736845005668,"user_tz":-345,"elapsed":3299,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"2df04c51-7493-4e0b-ce09-4230afa8dfaa"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["Training loss: 4.2679821968078615\n","Validation loss: 4.177527999877929\n"]}]},{"cell_type":"code","source":["\n","import time\n","\n","start_time = time.time()\n","\n","torch.manual_seed(123)\n","\n","optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n","\n","num_epochs = 2\n","\n","train_losses, val_losses, tokens_seen = train_model_simple(\n","    model, train_loader, val_loader, optimizer, device,\n","    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n","    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",")\n","\n","end_time = time.time()\n","execution_time_minutes = (end_time - start_time) / 60\n","print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QMXqON30Aq-x","executionInfo":{"status":"ok","timestamp":1736845188316,"user_tz":-345,"elapsed":182650,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"a51e0bf4-b2c5-4dcc-c1a3-1fd6ec46128e"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["Ep 1 (Step 000000): Train loss 2.994, Val loss 2.976\n","Ep 1 (Step 000005): Train loss 1.296, Val loss 1.235\n","Ep 1 (Step 000010): Train loss 0.933, Val loss 1.050\n","Ep 1 (Step 000015): Train loss 0.928, Val loss 0.984\n","Ep 1 (Step 000020): Train loss 0.850, Val loss 0.969\n","Ep 1 (Step 000025): Train loss 0.846, Val loss 0.941\n","Ep 1 (Step 000030): Train loss 0.872, Val loss 0.914\n","Ep 1 (Step 000035): Train loss 0.781, Val loss 0.881\n","Ep 1 (Step 000040): Train loss 0.732, Val loss 0.874\n","Ep 1 (Step 000045): Train loss 0.678, Val loss 0.859\n","Ep 1 (Step 000050): Train loss 0.723, Val loss 0.857\n","Ep 1 (Step 000055): Train loss 0.817, Val loss 0.830\n","Ep 1 (Step 000060): Train loss 0.783, Val loss 0.813\n","Ep 1 (Step 000065): Train loss 0.700, Val loss 0.799\n","Ep 1 (Step 000070): Train loss 0.582, Val loss 0.796\n","Ep 1 (Step 000075): Train loss 0.618, Val loss 0.799\n","Ep 1 (Step 000080): Train loss 0.663, Val loss 0.786\n","Ep 1 (Step 000085): Train loss 0.553, Val loss 0.767\n","Ep 1 (Step 000090): Train loss 0.610, Val loss 0.755\n","Ep 1 (Step 000095): Train loss 0.550, Val loss 0.752\n","Ep 1 (Step 000100): Train loss 0.547, Val loss 0.739\n","Ep 1 (Step 000105): Train loss 0.610, Val loss 0.732\n","Ep 1 (Step 000110): Train loss 0.601, Val loss 0.728\n","Ep 1 (Step 000115): Train loss 0.548, Val loss 0.724\n","Below is an instruction that describes a task.Write a response that appropriately completes the request.   Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'   Response: The chef cooks the meal every day.<|endoftext|>The following is an instruction that describes a task.Write a response that appropriately completes the request.   Instruction: Convert the active sentence to passive: 'The chef cooks the meal\n","Ep 2 (Step 000120): Train loss 0.469, Val loss 0.734\n","Ep 2 (Step 000125): Train loss 0.487, Val loss 0.757\n","Ep 2 (Step 000130): Train loss 0.485, Val loss 0.752\n","Ep 2 (Step 000135): Train loss 0.442, Val loss 0.737\n","Ep 2 (Step 000140): Train loss 0.449, Val loss 0.734\n","Ep 2 (Step 000145): Train loss 0.407, Val loss 0.737\n","Ep 2 (Step 000150): Train loss 0.412, Val loss 0.739\n","Ep 2 (Step 000155): Train loss 0.450, Val loss 0.733\n","Ep 2 (Step 000160): Train loss 0.454, Val loss 0.731\n","Ep 2 (Step 000165): Train loss 0.414, Val loss 0.736\n","Ep 2 (Step 000170): Train loss 0.354, Val loss 0.744\n","Ep 2 (Step 000175): Train loss 0.372, Val loss 0.741\n","Ep 2 (Step 000180): Train loss 0.437, Val loss 0.721\n","Ep 2 (Step 000185): Train loss 0.446, Val loss 0.720\n","Ep 2 (Step 000190): Train loss 0.372, Val loss 0.707\n","Ep 2 (Step 000195): Train loss 0.359, Val loss 0.687\n","Ep 2 (Step 000200): Train loss 0.340, Val loss 0.684\n","Ep 2 (Step 000205): Train loss 0.380, Val loss 0.681\n","Ep 2 (Step 000210): Train loss 0.403, Val loss 0.680\n","Ep 2 (Step 000215): Train loss 0.444, Val loss 0.687\n","Ep 2 (Step 000220): Train loss 0.327, Val loss 0.701\n","Ep 2 (Step 000225): Train loss 0.370, Val loss 0.718\n","Ep 2 (Step 000230): Train loss 0.316, Val loss 0.713\n","Below is an instruction that describes a task.Write a response that appropriately completes the request.   Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'   Response: The meal is cooked every day by the chef.<|endoftext|>The following is an instruction that describes a task.Write a response that appropriately completes the request.   Instruction: What is the capital of the United Kingdom?   Response:\n","Training completed in 3.05 minutes.\n"]}]},{"cell_type":"code","source":["epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n","plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":307},"id":"4lJ_f_W0As0j","executionInfo":{"status":"ok","timestamp":1736845189304,"user_tz":-345,"elapsed":991,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"9edadb77-9da0-47b9-fb2e-33f0a9541512"},"execution_count":49,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 500x300 with 2 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["## Response of the fine tuned model"],"metadata":{"id":"E1426DLjAw2c"}},{"cell_type":"code","source":["for entry in test_data[:10]:\n","\n","    input_text = format_input(entry)\n","\n","    token_ids = generate(\n","        model=model,\n","        idx=text_to_token_ids(input_text, tokenizer).to(device),\n","        max_new_tokens=256,\n","        context_size=BASE_CONFIG[\"context_length\"],\n","        eos_id=50256\n","    )\n","    generated_text = token_ids_to_text(token_ids, tokenizer)\n","    response_text = (\n","        generated_text[len(input_text):]\n","        .replace(\"### Response:\", \"\")\n","        .strip()\n",")\n","\n","    print(input_text)\n","    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n","    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n","    print(\"-------------------------------------\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F7a4dbGIAzY2","executionInfo":{"status":"ok","timestamp":1736845530350,"user_tz":-345,"elapsed":11472,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"bdfddd82-6ed3-4ea6-e7ab-a2c7708e5bd0"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["Below is an instruction that describes a task.Write a response that appropriately completes the request.\n","\n"," Instruction:\n","Rewrite the sentence using a simile.\n","\n"," Input:\n","The car is very fast.\n","\n","Correct response:\n",">> The car is as fast as lightning.\n","\n","Model response:\n",">> Response:\n","The car is as fast as a cheetah.\n","-------------------------------------\n","Below is an instruction that describes a task.Write a response that appropriately completes the request.\n","\n"," Instruction:\n","What type of cloud is typically associated with thunderstorms?\n","\n","Correct response:\n",">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n","\n","Model response:\n",">> Response:\n","A thunderstorm is typically associated with a type of cloud called a cumulus.\n","-------------------------------------\n","Below is an instruction that describes a task.Write a response that appropriately completes the request.\n","\n"," Instruction:\n","Name the author of 'Pride and Prejudice'.\n","\n","Correct response:\n",">> Jane Austen.\n","\n","Model response:\n",">> Response:\n","The author of 'Pride and Prejudice' is Jane Austen.\n","-------------------------------------\n","Below is an instruction that describes a task.Write a response that appropriately completes the request.\n","\n"," Instruction:\n","What is the periodic symbol for chlorine?\n","\n","Correct response:\n",">> The periodic symbol for chlorine is Cl.\n","\n","Model response:\n",">> Response:\n","The periodic symbol for chlorine is C.\n","-------------------------------------\n","Below is an instruction that describes a task.Write a response that appropriately completes the request.\n","\n"," Instruction:\n","Correct the punctuation in the sentence.\n","\n"," Input:\n","Its time to go home.\n","\n","Correct response:\n",">> The corrected sentence should be: 'It's time to go home.'\n","\n","Model response:\n",">> Response:\n","The punctuation in the sentence is incorrect.\n","-------------------------------------\n","Below is an instruction that describes a task.Write a response that appropriately completes the request.\n","\n"," Instruction:\n","Rewrite the sentence.\n","\n"," Input:\n","The lecture was delivered in a clear manner.\n","\n","Correct response:\n",">> The lecture was delivered clearly.\n","\n","Model response:\n",">> Response:\n","The lecture was delivered in a clear manner.\n","-------------------------------------\n","Below is an instruction that describes a task.Write a response that appropriately completes the request.\n","\n"," Instruction:\n","Generate a humorous anecdote.\n","\n","Correct response:\n",">> Why was the math book sad? Because it had too many problems!\n","\n","Model response:\n",">> Response:\n","I was at a party last night. I was having a great time, but then I saw a man in a black tuxedo. He was very popular, and everyone was enjoying themselves. I was very nervous, so I decided to go to his room. However, as I was walking in, I saw a black tuxedo on the bed. I was so excited, I decided to go to the room myself. However, as I was walking out, I saw a black tuxedo on the bed. I was so nervous, I decided to go to the room myself.\n","-------------------------------------\n","Below is an instruction that describes a task.Write a response that appropriately completes the request.\n","\n"," Instruction:\n","Identify the correct spelling: 'recieve' or 'receive'.\n","\n","Correct response:\n",">> The correct spelling is 'receive'.\n","\n","Model response:\n",">> Response:\n","The spelling of 'recieve' is 'receive'.\n","-------------------------------------\n","Below is an instruction that describes a task.Write a response that appropriately completes the request.\n","\n"," Instruction:\n","Create a sentence using the word 'nostalgia'.\n","\n","Correct response:\n",">> Nostalgia washed over her as she looked through the old photos.\n","\n","Model response:\n",">> Response:\n","The past few years have been very exciting for me. I was given the opportunity to travel and see new places.\n","-------------------------------------\n","Below is an instruction that describes a task.Write a response that appropriately completes the request.\n","\n"," Instruction:\n","Classify the following numbers as prime or composite.\n","\n"," Input:\n",": 11, 14, 19.\n","\n","Correct response:\n",">> Prime numbers: 11, 19\n","Composite numbers: 14\n","\n","Model response:\n",">> Response:\n","Prime: 11\n","Composite: 14\n","-------------------------------------\n"]}]},{"cell_type":"markdown","source":["## Model Evaluation"],"metadata":{"id":"mwaKtSuuBdI9"}},{"cell_type":"code","source":["from tqdm import tqdm\n","\n","for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n","\n","    input_text = format_input(entry)\n","\n","    token_ids = generate(\n","        model=model,\n","        idx=text_to_token_ids(input_text, tokenizer).to(device),\n","        max_new_tokens=256,\n","        context_size=BASE_CONFIG[\"context_length\"],\n","        eos_id=50256\n","    )\n","    generated_text = token_ids_to_text(token_ids, tokenizer)\n","    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n","\n","    test_data[i][\"model_response\"] = response_text\n","\n","\n","with open(\"instruction-data-with-response.json\", \"w\") as file:\n","    json.dump(test_data, file, indent=4)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-Sii1hoUBeyY","executionInfo":{"status":"ok","timestamp":1736845260277,"user_tz":-345,"elapsed":68265,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"b423eb57-c37c-455d-b8f7-bb873432ab17"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 110/110 [01:08<00:00,  1.61it/s]\n"]}]},{"cell_type":"code","source":["print(test_data[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r6phuEZOB80y","executionInfo":{"status":"ok","timestamp":1736845476274,"user_tz":-345,"elapsed":581,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"09741d7b-e887-4952-8ab5-17f97214f257"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["{'instruction': 'Rewrite the sentence using a simile.', 'input': 'The car is very fast.', 'output': 'The car is as fast as lightning.', 'model_response': 'Response:\\nThe car is as fast as a cheetah.'}\n"]}]},{"cell_type":"code","source":["import re\n","\n","file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL) }-sft.pth\"\n","torch.save(model.state_dict(), file_name)\n","print(f\"Model saved as {file_name}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dhq6UfzkCD7A","executionInfo":{"status":"ok","timestamp":1736845493536,"user_tz":-345,"elapsed":14879,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"9b25d280-8085-4d01-cb01-054e292c1f38"},"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["Model saved as gpt2-medium355M-sft.pth\n"]}]},{"cell_type":"code","source":["for entry in test_data[-40:]:\n","\n","    input_text = format_input(entry)\n","\n","    token_ids = generate(\n","        model=model,\n","        idx=text_to_token_ids(input_text, tokenizer).to(device),\n","        max_new_tokens=256,\n","        context_size=BASE_CONFIG[\"context_length\"],\n","        eos_id=50256\n","    )\n","    generated_text = token_ids_to_text(token_ids, tokenizer)\n","    response_text = (\n","        generated_text[len(input_text):]\n","        .replace(\"### Response:\", \"\")\n","        .strip()\n",")\n","\n","    print(input_text)\n","    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n","    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n","    print(\"-------------------------------------\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HDL_hfL2Eoj2","executionInfo":{"status":"ok","timestamp":1736845979062,"user_tz":-345,"elapsed":24985,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"f08b6ef8-1c80-4c79-9e77-e3a0f7241bed"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["Below is an instruction that describes a task.Write a response that appropriately completes the request.\n","\n"," Instruction:\n","Correct any spelling mistakes in the given sentence.\n","\n"," Input:\n","I prefer homemade cookies to store boaght.\n","\n","Correct response:\n",">> I prefer homemade cookies to store bought.\n","\n","Model response:\n",">> Response:\n","I prefer homemade cookies to store boaght.\n","-------------------------------------\n","Below is an instruction that describes a task.Write a response that appropriately completes the request.\n","\n"," Instruction:\n","Generate a sentence using the word 'transient'.\n","\n","Correct response:\n",">> His stay in the city was transient, lasting only a couple of days.\n","\n","Model response:\n",">> Response:\n","She was seen by a passerby as she passed by.\n","-------------------------------------\n","Below is an instruction that describes a task.Write a response that appropriately completes the request.\n","\n"," Instruction:\n","Translate 'I am lost' into Italian.\n","\n","Correct response:\n",">> The Italian translation of 'I am lost' is 'Mi sono perso' (if male) or 'Mi sono persa' (if female).\n","\n","Model response:\n",">> Response:\n","The Italian translation of 'I am lost' is 'Il è amo'.\n","-------------------------------------\n","Below is an instruction that describes a task.Write a response that appropriately completes the request.\n","\n"," Instruction:\n","Classify this text as a technical document or a narrative.\n","\n"," Input:\n","This manual provides instructions for installing the software.\n","\n","Correct response:\n",">> Technical document\n","\n","Model response:\n",">> Response:\n","The document is a technical document.\n","-------------------------------------\n","Below is an instruction that describes a task.Write a response that appropriately completes the request.\n","\n"," Instruction:\n","Sort the following list in descending order.\n","\n"," Input:\n","10, 2, 25, 16, 7\n","\n","Correct response:\n",">> 25, 16, 10, 7, 2.\n","\n","Model response:\n",">> Response:\n","The list of the following would be in descending order: 2, 25, 10.\n","-------------------------------------\n","Below is an instruction that describes a task.Write a response that appropriately completes the request.\n","\n"," Instruction:\n","Translate 'Can I have some water?' into French.\n","\n","Correct response:\n",">> Puis-je avoir de l'eau?\n","\n","Model response:\n",">> Response:\n","The French translation of 'Can I have some water?' is 'Comment ça va?'.\n","-------------------------------------\n","Below is an instruction that describes a task.Write a response that appropriately completes the request.\n","\n"," Instruction:\n","Create a simile with the word 'as cold as'.\n","\n","Correct response:\n",">> Her hands were as cold as ice.\n","\n","Model response:\n",">> Response:\n","The temperature of the room was as cold as ice.\n","-------------------------------------\n","Below is an instruction that describes a task.Write a response that appropriately completes the request.\n","\n"," Instruction:\n","Classify the following words by their grammatical categories: swim, beautiful, quickly\n","\n","Correct response:\n",">> Swim: Verb\n","Beautiful: Adjective\n","Quickly: Adverb\n","\n","Model response:\n",">> Response:\n","The words swim and beautiful are in the declarative sentence 'swim quickly'.\n","-------------------------------------\n","Below is an instruction that describes a task.Write a response that appropriately completes the request.\n","\n"," Instruction:\n","Calculate the density of an object with a mass of 15 grams and a volume of 5 cubic centimeters.\n","\n","Correct response:\n",">> The density of the object is 3 grams per cubic centimeter.\n","\n","Model response:\n",">> Response:\n","The density of the object is 15 grams/cc.\n","-------------------------------------\n","Below is an instruction that describes a task.Write a response that appropriately completes the request.\n","\n"," Instruction:\n","What is the abbreviation for 'Master of Business Administration'?\n","\n","Correct response:\n",">> The abbreviation for 'Master of Business Administration' is MBA.\n","\n","Model response:\n",">> Response:\n","The abbreviation for 'Master of Business Administration' is MBA.\n","-------------------------------------\n","Below is an instruction that describes a task.Write a response that appropriately completes the request.\n","\n"," Instruction:\n","Convert the following number from Roman numerals: IX.\n","\n","Correct response:\n",">> The number IX in Roman numerals is 9.\n","\n","Model response:\n",">> 5 to Roman numerals: 5.\n","\n"," Response:\n","The Roman numerals for the given number are 5.\n","-------------------------------------\n","Below is an instruction that describes a task.Write a response that appropriately completes the request.\n","\n"," Instruction:\n","What is the opposite of 'horizontal'?\n","\n","Correct response:\n",">> The opposite of 'horizontal' is 'vertical'.\n","\n","Model response:\n",">> Response:\n","The opposite of 'horizontal' is 'vertical'.\n","-------------------------------------\n","Below is an instruction that describes a task.Write a response that appropriately completes the request.\n","\n"," Instruction:\n","Translate 'Where can I buy tickets?' into Italian.\n","\n","Correct response:\n",">> The Italian translation for 'Where can I buy tickets?' is 'Dove posso comprare i biglietti?'\n","\n","Model response:\n",">> Response:\n","The Italian translation of 'Where can I buy tickets?' is 'Ti amo?'.\n","-------------------------------------\n","Below is an instruction that describes a task.Write a response that appropriately completes the request.\n","\n"," Instruction:\n","Rewrite the following sentence to replace any clichés.\n","\n"," Input:\n","He was as cool as a cucumber.\n","\n","Correct response:\n",">> He remained very calm.\n","\n","Model response:\n",">> Response:\n","He was as cool as a cucumber.\n","-------------------------------------\n","Below is an instruction that describes a task.Write a response that appropriately completes the request.\n","\n"," Instruction:\n","Identify the main verb in the sentence.\n","\n"," Input:\n","The dog barked loudly.\n","\n","Correct response:\n",">> The main verb in the sentence is 'barked'.\n","\n","Model response:\n",">> Response:\n","The main verb in the sentence is 'bark'.\n","-------------------------------------\n","Below is an instruction that describes a task.Write a response that appropriately completes the request.\n","\n"," Instruction:\n","Generate a sentence using the word 'elucidate'.\n","\n","Correct response:\n",">> The professor attempted to elucidate the complex topic for his students.\n","\n","Model response:\n",">> Response:\n","The teacher was able to quickly figure out the sentence.\n","-------------------------------------\n","Below is an instruction that describes a task.Write a response that appropriately completes the request.\n","\n"," Instruction:\n","Correct the sentence.\n","\n"," Input:\n","Me and my friend went to the store.\n","\n","Correct response:\n",">> My friend and I went to the store.\n","\n","Model response:\n",">> Response:\n","We went to the store.\n","-------------------------------------\n","Below is an instruction that describes a task.Write a response that appropriately completes the request.\n","\n"," Instruction:\n","What is the formula for calculating work done?\n","\n","Correct response:\n",">> The formula for calculating work done is work = force × distance.\n","\n","Model response:\n",">> Response:\n","The formula for calculating work done is W = (C + B)2.\n","-------------------------------------\n","Below is an instruction that describes a task.Write a response that appropriately completes the request.\n","\n"," Instruction:\n","What is the chemical formula for ammonium nitrate?\n","\n","Correct response:\n",">> The chemical formula for ammonium nitrate is NH4NO3.\n","\n","Model response:\n",">> Response:\n","The chemical formula for ammonium nitrate is NH3.\n","-------------------------------------\n","Below is an instruction that describes a task.Write a response that appropriately completes the request.\n","\n"," Instruction:\n","What is the molecular formula for water?\n","\n","Correct response:\n",">> The molecular formula for water is H2O.\n","\n","Model response:\n",">> Response:\n","The molecular formula for water is H2O2.\n","-------------------------------------\n","Below is an instruction that describes a task.Write a response that appropriately completes the request.\n","\n"," Instruction:\n","Rewrite the given sentence to describe the same thing in a positive way.\n","\n"," Input:\n","The food was not good.\n","\n","Correct response:\n",">> The food could use some improvement.\n","\n","Model response:\n",">> Response:\n","The food was not good.\n","-------------------------------------\n","Below is an instruction that describes a task.Write a response that appropriately completes the request.\n","\n"," Instruction:\n","What is the opposite of 'lazy'?\n","\n","Correct response:\n",">> The opposite of 'lazy' is 'diligent'.\n","\n","Model response:\n",">> Response:\n","The opposite of 'lazy' is 'attentive'.\n","-------------------------------------\n","Below is an instruction that describes a task.Write a response that appropriately completes the request.\n","\n"," Instruction:\n","Name three essential vitamins for human health.\n","\n","Correct response:\n",">> 1. Vitamin A\n","2. Vitamin C\n","3. Vitamin D\n","\n","Model response:\n",">> Response:\n","1. Calcium\n","2. Iron\n","3. Magnesium\n","-------------------------------------\n","Below is an instruction that describes a task.Write a response that appropriately completes the request.\n","\n"," Instruction:\n","Define the term 'simile'.\n","\n","Correct response:\n",">> A simile is a figure of speech that directly compares two different things, often introduced with the words 'like' or 'as'.\n","\n","Model response:\n",">> Response:\n","A simile is a figurative device used to describe a figure of speech.\n","-------------------------------------\n","Below is an instruction that describes a task.Write a response that appropriately completes the request.\n","\n"," Instruction:\n","What is the boiling point of chlorine in Celsius?\n","\n","Correct response:\n",">> The boiling point of chlorine is -34 degrees Celsius.\n","\n","Model response:\n",">> Response:\n","The boiling point of chlorine is -38.5 degrees Celsius.\n","-------------------------------------\n","Below is an instruction that describes a task.Write a response that appropriately completes the request.\n","\n"," Instruction:\n","Translate 'My name is' into French.\n","\n","Correct response:\n",">> The French translation of 'My name is' is 'Je m'appelle'.\n","\n","Model response:\n",">> Response:\n","The French translation of 'My name is' is 'Comment ça va?'.\n","-------------------------------------\n","Below is an instruction that describes a task.Write a response that appropriately completes the request.\n","\n"," Instruction:\n","Convert 200 centimeters to meters.\n","\n","Correct response:\n",">> 200 centimeters is 2 meters.\n","\n","Model response:\n",">> Response:\n","200 centimeters is 0.2 meters.\n","-------------------------------------\n","Below is an instruction that describes a task.Write a response that appropriately completes the request.\n","\n"," Instruction:\n","What is the chemical symbol for zinc?\n","\n","Correct response:\n",">> Zn.\n","\n","Model response:\n",">> Response:\n","Zinc is Zn.\n","-------------------------------------\n","Below is an instruction that describes a task.Write a response that appropriately completes the request.\n","\n"," Instruction:\n","What is the formula for calculating force?\n","\n","Correct response:\n",">> The formula for calculating force is Force = mass x acceleration.\n","\n","Model response:\n",">> Response:\n","The formula for calculating force is F = M * (1/2) * (1/3) * (1/4) * (1/5) * (1/6) * (1/7) * (1/8) * (1/9) * (1/10) * (m/s)\n","-------------------------------------\n","Below is an instruction that describes a task.Write a response that appropriately completes the request.\n","\n"," Instruction:\n","Generate a sentence using the word 'innovative'.\n","\n","Correct response:\n",">> The company's innovative approach set it apart from its competitors.\n","\n","Model response:\n",">> Response:\n","She is always thinking of new ideas.\n","-------------------------------------\n","Below is an instruction that describes a task.Write a response that appropriately completes the request.\n","\n"," Instruction:\n","Generate a sentence using the word 'generous'.\n","\n","Correct response:\n",">> He is very generous and always helps those in need.\n","\n","Model response:\n",">> Response:\n","She was very generous and always provided for her friends.\n","-------------------------------------\n","Below is an instruction that describes a task.Write a response that appropriately completes the request.\n","\n"," Instruction:\n","What is an antonym of 'sharp'?\n","\n","Correct response:\n",">> An antonym of 'sharp' is 'dull'.\n","\n","Model response:\n",">> Response:\n","An antonym of 'sharp' is 'soft'.\n","-------------------------------------\n","Below is an instruction that describes a task.Write a response that appropriately completes the request.\n","\n"," Instruction:\n","Describe the basic structure of a neuron.\n","\n","Correct response:\n",">> A neuron consists of three main parts: the cell body, which contains the nucleus; dendrites, which receive signals from other neurons; and an axon, which transmits signals to other neurons, muscles, or glands.\n","\n","Model response:\n",">> Response:\n","A neuron is a type of synapse in the brain. It is a synapse between two neurons.\n","-------------------------------------\n","Below is an instruction that describes a task.Write a response that appropriately completes the request.\n","\n"," Instruction:\n","Translate 'see you later' into Spanish.\n","\n","Correct response:\n",">> Hasta luego\n","\n","Model response:\n",">> Response:\n","Estoy están los nombres.\n","-------------------------------------\n","Below is an instruction that describes a task.Write a response that appropriately completes the request.\n","\n"," Instruction:\n","What are the first 10 elements of the Fibonacci sequence?\n","\n","Correct response:\n",">> 0, 1, 1, 2, 3, 5, 8, 13, 21, 34.\n","\n","Model response:\n",">> Response:\n","The first 10 elements of the Fibonacci sequence are: 1, 3, 5, 7, 11.\n","-------------------------------------\n","Below is an instruction that describes a task.Write a response that appropriately completes the request.\n","\n"," Instruction:\n","What is an antonym of 'transparent'?\n","\n","Correct response:\n",">> An antonym of 'transparent' is 'opaque'.\n","\n","Model response:\n",">> Response:\n","An antonym of 'transparent' is 'illuminated'.\n","-------------------------------------\n","Below is an instruction that describes a task.Write a response that appropriately completes the request.\n","\n"," Instruction:\n","What is the past tense of 'think'?\n","\n","Correct response:\n",">> The past tense of 'think' is 'thought'.\n","\n","Model response:\n",">> Response:\n","The past tense of 'think' is 'to think'.\n","-------------------------------------\n","Below is an instruction that describes a task.Write a response that appropriately completes the request.\n","\n"," Instruction:\n","Classify each sentence as either declarative, interrogative, imperative, or exclamatory.\n","\n"," Input:\n","Please open the door.\n","\n","Correct response:\n",">> The classification of the sentence 'Please open the door.' is imperative.\n","\n","Model response:\n",">> Response:\n","The door was opened by the speaker.\n","-------------------------------------\n","Below is an instruction that describes a task.Write a response that appropriately completes the request.\n","\n"," Instruction:\n","Rewrite the sentence to use a negative adverb.\n","\n"," Input:\n","She always remembers to call.\n","\n","Correct response:\n",">> She never forgets to call.\n","\n","Model response:\n",">> Response:\n","She always remembers to call.\n","-------------------------------------\n","Below is an instruction that describes a task.Write a response that appropriately completes the request.\n","\n"," Instruction:\n","Convert 50 miles per hour to kilometers per hour.\n","\n","Correct response:\n",">> 50 miles per hour is approximately 80.47 kilometers per hour.\n","\n","Model response:\n",">> Response:\n","50 miles per hour is approximately 32.5 kilometers per hour.\n","-------------------------------------\n"]}]}]}